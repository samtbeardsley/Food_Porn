{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import json\n",
    "import os\n",
    "import praw\n",
    "import requests\n",
    "import datetime as dt\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API arguments\n",
    "CLIENT_ID = '8InJgsdPcLSGUQ'\n",
    "CLIENT_SECRET = 'MFjtDa8dUZf-Cq75UHl2XMfQmoA'\n",
    "USER_AGENT = 'subreddit top post scraping by /u/samjabroni'\n",
    "USERNAME = 'samjabroni'\n",
    "PASSWORD = 'cxFw$u#x55AdkBebmG7D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.0.0 of praw is outdated. Version 7.1.0 was released Tuesday June 23, 2020.\n"
     ]
    }
   ],
   "source": [
    "# create API object\n",
    "reddit = praw.Reddit(client_id=CLIENT_ID,\n",
    "                     client_secret=CLIENT_SECRET,\n",
    "                     user_agent=USER_AGENT,\n",
    "                     username=USERNAME,\n",
    "                     password=PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.storybench.org/how-to-scrape-reddit-with-python/\n",
    "\n",
    "#def make_subreddit_df(subreddit, limit):\n",
    "    \n",
    "#    subreddit = reddit.subreddit(subreddit)\n",
    "\n",
    "#    top_posts = subreddit.top(limit=limit)\n",
    "\n",
    "#    post_dict = { \"title\":[], \"score\":[],\n",
    "#                 \"id\":[], \"url\":[], \"num_comments\":[],\n",
    "#                 \"created\":[]}\n",
    "\n",
    "#    for submission in top_posts:\n",
    "#        post_dict[\"title\"].append(submission.title)\n",
    "#        post_dict[\"score\"].append(submission.score)\n",
    "#        post_dict[\"id\"].append(submission.id)\n",
    "#        post_dict[\"url\"].append(submission.url)\n",
    "#        post_dict[\"num_comments\"].append(submission.num_comments)\n",
    "#        post_dict[\"created\"].append(dt.datetime.fromtimestamp(submission.created))\n",
    "    \n",
    "#    subreddit_df = pd.DataFrame(data=post_dict)\n",
    "    \n",
    "#    return subreddit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframes\n",
    "fp_df = make_subreddit_df(\"FoodPorn\", limit=1000)\n",
    "sfp_df = make_subreddit_df(\"shittyfoodporn\", limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fp_df.to_csv('Data/foodporn.csv', index=False)\n",
    "#fp_df.to_csv('Data/shittyfoodporn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sam/Desktop/FoodPorn'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream submissions\n",
    "for submission in reddit.subreddit(\"all\").stream.submissions():\n",
    "    print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_df(subreddit, n_pages=1):\n",
    "    \n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    n = 0\n",
    "    url = 'https://old.reddit.com/r/' + str(subreddit) +'/top.json'\n",
    "    \n",
    "    post_dict = { \"title\":[], \"created\":[],\n",
    "                 \"id\":[], \"url\":[],\n",
    "                 \"score\":[], \"num_comments\":[]}\n",
    "    \n",
    "    while n < n_pages:\n",
    "        try:\n",
    "            r = requests.get(url, headers=headers)\n",
    "            js = r.json()\n",
    "        \n",
    "            for post in range(len(js['data']['children'])):\n",
    "                post_dict['title'].append(js['data']['children'][post]['data']['title'])\n",
    "                post_dict['score'].append(js['data']['children'][post]['data']['score'])\n",
    "                post_dict['id'].append(js['data']['children'][post]['data']['id'])\n",
    "                post_dict['url'].append(js['data']['children'][post]['data']['url'])\n",
    "                post_dict['num_comments'].append(js['data']['children'][post]['data']['num_comments'])\n",
    "                post_dict['created'].append(dt.datetime.fromtimestamp(js['data']['children'][post]['data']['created']))\n",
    "            \n",
    "            url = 'https://old.reddit.com/r/' + str(subreddit) + '.json' + '?count=' + str(25*(n+1)) + '&after=' + str(js['data']['after']) \n",
    "        \n",
    "        except:\n",
    "            print(f'error at page {n}')\n",
    "            continue\n",
    "        \n",
    "        n += 1\n",
    "        time.sleep(3)\n",
    "        \n",
    "    subreddit_df = pd.DataFrame(data=post_dict)\n",
    "    \n",
    "    return subreddit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df = get_top_df('FoodPorn',800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jpg                   18818\n",
       "png                     315\n",
       "gif                      44\n",
       "jpeg                     23\n",
       "com/vL3kddD              23\n",
       "com/tVLIORa              23\n",
       "com/H9ai8dW              23\n",
       "com/Ti2VhnS              23\n",
       "com/VDE3Tr0              22\n",
       "com/3Tvd9Yn              22\n",
       "com/6HEr5ZZ              22\n",
       "com/COdUFsE              22\n",
       "com/IKJuKQz              22\n",
       "com/dMsqkIP              22\n",
       "com/ZzjXfEq              22\n",
       "com/gallery/iwpvob       22\n",
       "com/hku43QJ              22\n",
       "com/kmCpEqO              22\n",
       "com/ooxJzeV              22\n",
       "com/uCXOz0T              22\n",
       "com/2SKje5q              22\n",
       "com/YpKZCAA               9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test = []\n",
    "#for url in fp_df.url:\n",
    "#    test.append(str.split(str(url),'.')[-1])\n",
    "#testdf = pd.DataFrame(test)\n",
    "#testdf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df.to_csv('Data/foodporn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19587 entries, 0 to 19586\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   title         19587 non-null  object        \n",
      " 1   created       19587 non-null  datetime64[ns]\n",
      " 2   id            19587 non-null  object        \n",
      " 3   url           19587 non-null  object        \n",
      " 4   score         19587 non-null  int64         \n",
      " 5   num_comments  19587 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(2), object(3)\n",
      "memory usage: 918.3+ KB\n"
     ]
    }
   ],
   "source": [
    "fp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfp_df = get_top_df('shittyfoodporn',800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19754 entries, 0 to 19753\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   title         19754 non-null  object        \n",
      " 1   created       19754 non-null  datetime64[ns]\n",
      " 2   id            19754 non-null  object        \n",
      " 3   url           19754 non-null  object        \n",
      " 4   score         19754 non-null  int64         \n",
      " 5   num_comments  19754 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(2), object(3)\n",
      "memory usage: 926.1+ KB\n"
     ]
    }
   ],
   "source": [
    "sfp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfp_df.to_csv('Data/shittyfoodporn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sam/Desktop/FoodPorn'"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('FoodPorn')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_subreddit_images(subreddit_df, directory):\n",
    "    \"\"\"downloads all static images (png & jpg) from specified subreddit dataframe to desired directory\"\"\"\n",
    "    \n",
    "    headers = {'user-agent': 'image_downloader'}\n",
    "    url_dict = {}\n",
    "    \n",
    "    # checks if directory exists, if not makes one\n",
    "    current_path = os.getcwd()\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    os.chdir(directory)\n",
    "    \n",
    "    # find urls and create file names from unique post id\n",
    "    for row in subreddit_df.itertuples():\n",
    "        filename = f\"{row[0]}.{str.split(str(row[4]), sep='.')[-1]}\"\n",
    "        url =row[4]\n",
    "        url_dict[filename] = url\n",
    "    \n",
    "    # iterates over static images in dict and saves to file\n",
    "    for filename, url in tqdm(url_dict.items()):\n",
    "        # check if url is png or jpg\n",
    "        if (str.split(filename, sep='.')[-1] == 'jpg') or (str.split(filename, sep='.')[-1] =='png'):\n",
    "            r = requests.get(url, headers=headers, stream=True)\n",
    "       \n",
    "            with open(filename, 'wb') as fd:\n",
    "                for chunk in r.iter_content(chunk_size=128):\n",
    "                    fd.write(chunk)\n",
    "            time.sleep(3)\n",
    "        pass\n",
    "    \n",
    "    os.chdir(current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19587/19587 [6:48:57<00:00,  1.25s/it]  \n"
     ]
    }
   ],
   "source": [
    "download_subreddit_images(fp_df,'Images/Food_Porn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15423/15423 [13:27:09<00:00,  3.14s/it]  \n"
     ]
    }
   ],
   "source": [
    "download_subreddit_images(sfp_df.iloc[4331:],'Images/Shitty_Food_Porn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA ideas\n",
    "Pixel wise absolute difference\n",
    "Color channels\n",
    "Contrast\n",
    "Intensity\n",
    "Color change within image\n",
    "Text?\n",
    "\n",
    "size - by pixels (and resolution?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
